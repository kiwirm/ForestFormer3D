#!/usr/bin/env bash
set -euo pipefail

# End-to-end single-scene pipeline:
# LAS + polygons -> labeled LAS -> single PLY per split -> derived/bin -> info PKLs

ROOT_DIR=$(cd "$(dirname "${BASH_SOURCE[0]}")/.." && pwd)
VENV_ACTIVATE="$ROOT_DIR/.venv/bin/activate"

export PYTHONPATH="$ROOT_DIR"

echo "Cleaning single-scene outputs (PLYs, derived arrays, processed bins, infos)..."
rm -f "$ROOT_DIR/data/labeled/plys/train_val/"train_scene.ply
rm -f "$ROOT_DIR/data/labeled/plys/test/"test_scene.ply
rm -f "$ROOT_DIR/data/derived/instance_data"/train_scene_*.npy
rm -f "$ROOT_DIR/data/derived/instance_data"/test_scene_*.npy
rm -f "$ROOT_DIR/data/derived/infos"/scene_oneformer3d_infos_*.pkl
rm -f "$ROOT_DIR/data/processed/points"/train_scene.bin "$ROOT_DIR/data/processed/points"/test_scene.bin
rm -f "$ROOT_DIR/data/processed/instance_mask"/train_scene.bin "$ROOT_DIR/data/processed/instance_mask"/test_scene.bin
rm -f "$ROOT_DIR/data/processed/semantic_mask"/train_scene.bin "$ROOT_DIR/data/processed/semantic_mask"/test_scene.bin
rm -f "$ROOT_DIR/data/splits/scene"/scene_train_list.txt "$ROOT_DIR/data/splits/scene"/scene_val_list.txt "$ROOT_DIR/data/splits/scene"/scene_test_list.txt

TRAIN_LAS_INPUT="${TRAIN_LAS_INPUT:-$ROOT_DIR/data/raw/las/cass/cass.segment.crop.train.las}"
TEST_LAS_INPUT="${TEST_LAS_INPUT:-$ROOT_DIR/data/raw/las/cass/cass.segment.crop.test.las}"
VECTORS_SHAPE="${VECTORS_SHAPE:-$ROOT_DIR/data/raw/vectors/tree_crowns.shp}"
TRAIN_LABELED_LAS="${TRAIN_LABELED_LAS:-$ROOT_DIR/data/intermediate/train_labeled.las}"
TEST_LABELED_LAS="${TEST_LABELED_LAS:-$ROOT_DIR/data/intermediate/test_labeled.las}"

TARGET_CRS="${TARGET_CRS:-EPSG:2134}"
TREE_ID_COL="${TREE_ID_COL:-tree_id}"
TRAIN_SCENE_NAME="${TRAIN_SCENE_NAME:-train_scene}"
TEST_SCENE_NAME="${TEST_SCENE_NAME:-test_scene}"
SPLITS_DIR="$ROOT_DIR/data/splits/scene"
TRAIN_PLY_DIR="$ROOT_DIR/data/labeled/plys/train_val"
TEST_PLY_DIR="$ROOT_DIR/data/labeled/plys/test"
DERIVED_INSTANCE_DIR="$ROOT_DIR/data/derived/instance_data"
DERIVED_INFOS_DIR="$ROOT_DIR/data/derived/infos"
PROCESSED_POINTS_DIR="$ROOT_DIR/data/processed/points"
PROCESSED_INSTANCE_MASK_DIR="$ROOT_DIR/data/processed/instance_mask"
PROCESSED_SEMANTIC_MASK_DIR="$ROOT_DIR/data/processed/semantic_mask"
INTERMEDIATE_DIR="$ROOT_DIR/data/intermediate"

mkdir -p \
  "$SPLITS_DIR" \
  "$TRAIN_PLY_DIR" \
  "$TEST_PLY_DIR" \
  "$DERIVED_INSTANCE_DIR" \
  "$DERIVED_INFOS_DIR" \
  "$PROCESSED_POINTS_DIR" \
  "$PROCESSED_INSTANCE_MASK_DIR" \
  "$PROCESSED_SEMANTIC_MASK_DIR" \
  "$INTERMEDIATE_DIR"

# 1) Assign tree_id and convert train LAS -> single train scene PLY
python tools/datasets/assign_tree_id_from_shp.py \
  --las "$TRAIN_LAS_INPUT" \
  --gt "$VECTORS_SHAPE" \
  --out "$TRAIN_LABELED_LAS" \
  --tree-id-col "$TREE_ID_COL" \
  --target-crs "$TARGET_CRS"

python tools/datasets/las_to_ply.py \
  "$TRAIN_LABELED_LAS" \
  "$TRAIN_PLY_DIR/$TRAIN_SCENE_NAME.ply"

# Train/val both point at the single train scene.
printf "%s\n" "$TRAIN_SCENE_NAME" > "$SPLITS_DIR/scene_train_list.txt"
printf "%s\n" "$TRAIN_SCENE_NAME" > "$SPLITS_DIR/scene_val_list.txt"

# 2) Optional test scene: only process if cass.segment.crop.test.las exists
if [[ -f "$TEST_LAS_INPUT" ]]; then
  python tools/datasets/assign_tree_id_from_shp.py \
    --las "$TEST_LAS_INPUT" \
    --gt "$VECTORS_SHAPE" \
    --out "$TEST_LABELED_LAS" \
    --tree-id-col "$TREE_ID_COL" \
    --target-crs "$TARGET_CRS"

  python tools/datasets/las_to_ply.py \
    "$TEST_LABELED_LAS" \
    "$TEST_PLY_DIR/$TEST_SCENE_NAME.ply"

  printf "%s\n" "$TEST_SCENE_NAME" > "$SPLITS_DIR/scene_test_list.txt"
else
  : > "$SPLITS_DIR/scene_test_list.txt"
  echo "Test LAS not found at $TEST_LAS_INPUT; scene_test_list.txt left empty."
fi

# 3) Build derived arrays / bins
python tools/datasets/preprocess_dataset.py \
  --train_scan_names_file data/splits/scene/scene_train_list.txt \
  --val_scan_names_file data/splits/scene/scene_val_list.txt \
  --test_scan_names_file data/splits/scene/scene_test_list.txt

# 4) Build PKL infos
python tools/prep/build_infos.py scene \
  --extra-tag scene

echo "Done. Single-scene data is ready."
